# src/tutor_app/web/pages/5_ğŸ“Š_Analysis_Dashboard.py
import streamlit as st
import json
import datetime
import pandas as pd
from src.tutor_app.db.session import SessionLocal
from src.tutor_app.db.models import KnowledgeSource
# ã€ä¼˜åŒ–1ã€‘å¯¼å…¥æ‰€æœ‰éœ€è¦çš„å‡½æ•°
from src.tutor_app.analytics.dashboard_data import (
    get_practice_summary, 
    get_performance_by_source, 
    get_mistake_notebook,
    get_srs_review_forecast,
    get_hardest_questions
)
from src.tutor_app.web.components.task_monitor import display_global_task_monitor

st.set_page_config(page_title="å­¦ä¹ åˆ†æ", layout="wide")
display_global_task_monitor()
st.title("ğŸ“Š å­¦ä¹ åˆ†æä»ªè¡¨ç›˜")

db = SessionLocal()

# --- å…¨å±€ç­›é€‰å™¨ (ä¿æŒä¸å˜) ---
with st.container(border=True):
    st.subheader("ç­›é€‰å™¨")
    
    all_sources = db.query(KnowledgeSource).all()
    source_options = {s.filename: s.id for s in all_sources}
    selected_sources_names = st.multiselect("é€‰æ‹©åˆ†æèŒƒå›´ï¼ˆçŸ¥è¯†åº“ï¼‰:", options=list(source_options.keys()), default=list(source_options.keys()))
    selected_source_ids = [source_options[name] for name in selected_sources_names]

    col1, col2 = st.columns(2)
    today = datetime.date.today()
    start_date = col1.date_input("å¼€å§‹æ—¥æœŸ", today - datetime.timedelta(days=30))
    end_date = col2.date_input("ç»“æŸæ—¥æœŸ", today)

# --- ã€ä¼˜åŒ–2ã€‘è·å–æ‰€æœ‰åˆ†ææ‰€éœ€çš„æ•°æ® ---
summary = get_practice_summary(db, source_ids=selected_source_ids, start_date=start_date, end_date=end_date)
performance_df = get_performance_by_source(db, source_ids=selected_source_ids, start_date=start_date, end_date=end_date)
grouped_mistakes = get_mistake_notebook(db, source_ids=selected_source_ids, start_date=start_date, end_date=end_date)
# è°ƒç”¨æ–°å‡½æ•°è·å–è®°å¿†å¥åº·åº¦æ•°æ®
review_forecast_df = get_srs_review_forecast(db)
hardest_questions = get_hardest_questions(db)
db.close()

# --- ã€ä¼˜åŒ–3ã€‘å¢åŠ æ–°çš„Tabå¹¶é‡æ–°æ’åº ---
tab1, tab2, tab3, tab4 = st.tabs([
    f"ğŸ“ˆ æ•°æ®æ€»è§ˆ", 
    f"ğŸ§  è®°å¿†å¥åº·åº¦", # æ–°å¢çš„Tab
    f"ğŸ“š å„çŸ¥è¯†åº“è¡¨ç°", 
    f"ğŸ“’ é”™é¢˜æœ¬ ({sum(len(data['mistakes']) for data in grouped_mistakes.values())})"
])

with tab1:
    st.header("æ•°æ®æ€»è§ˆ")
    st.info(f"ä»¥ä¸‹æ•°æ®ç»Ÿè®¡èŒƒå›´ä¸º **{start_date}** è‡³ **{end_date}**")
    cols = st.columns(3)
    cols[0].metric("æ€»ç»ƒä¹ æ¬¡æ•°", summary["total"])
    cols[1].metric("æ€»æ­£ç¡®æ¬¡æ•°", summary["correct"])
    cols[2].metric("æ€»æ­£ç¡®ç‡", f"{summary['accuracy']}%")

# --- ã€ä¼˜åŒ–4ã€‘æ¸²æŸ“â€œè®°å¿†å¥åº·åº¦â€æ–°é¡µé¢çš„å†…å®¹ ---
with tab2:
    st.header("è®°å¿†å¥åº·åº¦åˆ†æ")
    st.info("æ­¤é¡µé¢åŸºäºæ‚¨çš„â€œæ™ºèƒ½å¤ä¹ â€å†å²ï¼Œæ´å¯Ÿæ‚¨çš„è®°å¿†è§„å¾‹ã€‚")

    st.subheader("ğŸ—“ï¸ æœªæ¥30å¤©å¤ä¹ å‹åŠ›å›¾")
    if not review_forecast_df.empty:
        st.bar_chart(review_forecast_df)
    else:
        st.write("æœªæ¥30å¤©å†…æ²¡æœ‰å¾…å¤ä¹ çš„é¢˜ç›®ã€‚")
    
    st.divider()

    st.subheader("ğŸ§  åå¤§â€œé¡½å›ºâ€çŸ¥è¯†ç‚¹")
    st.warning("è¿™äº›æ˜¯æ‚¨æœ€å®¹æ˜“å¿˜è®°æˆ–æ„Ÿåˆ°å›°éš¾çš„é¢˜ç›®ï¼ˆåŸºäºç®€æ˜“åº¦å› å­ `ease_factor` æ’åºï¼‰ï¼Œè¯·é‡ç‚¹å…³æ³¨ã€‚")
    if hardest_questions:
        for i, (question, stats) in enumerate(hardest_questions):
            with st.expander(f"**Top {i+1}:** {json.loads(question.content)['question'][:50]}..."):
                st.error(f"**é¢˜ç›®**:{json.loads(question.content)['question']}")
                st.info(f"**ç­”æ¡ˆ**:{json.loads(question.answer)}")
                st.divider()
                stat_cols = st.columns(3)
                stat_cols[0].metric("ç®€æ˜“åº¦å› å­", f"{stats.ease_factor:.2f}", help="å€¼è¶Šä½è¡¨ç¤ºè¶Šéš¾ï¼Œæœ€ä½ä¸º1.3")
                stat_cols[1].metric("æ­£ç¡®å¤ä¹ æ¬¡æ•°", stats.repetitions)
                stat_cols[2].metric("ä¸‹æ¬¡å¤ä¹ é—´éš”", f"{stats.interval} å¤©")
    else:
        st.write("æš‚æ— è®°å¿†æ•°æ®ï¼Œè¯·å…ˆåœ¨â€œæ™ºèƒ½å¤ä¹ â€æ¨¡å¼ä¸‹è¿›è¡Œç»ƒä¹ ã€‚")


with tab3:
    st.header("å„çŸ¥è¯†åº“è¡¨ç°")
    if not performance_df.empty:
        st.dataframe(performance_df, use_container_width=True)
        st.bar_chart(performance_df.set_index('çŸ¥è¯†æº')['æ­£ç¡®ç‡'])
    else:
        st.info("æ‰€é€‰èŒƒå›´å†…æš‚æ— ç»ƒä¹ æ•°æ®ã€‚")

with tab4:
    st.header("é”™é¢˜æœ¬")
    all_mistake_ids = [q.id for data in grouped_mistakes.values() for q, log in data['mistakes']]
    
    if all_mistake_ids:
        if st.button("ğŸ§  å¼€å§‹æœ¬æ¬¡é”™é¢˜é›†è®­", type="primary", use_container_width=True):
            st.session_state.practice_from_mistakes = all_mistake_ids
            st.switch_page("pages/3_âœï¸_Practice_Mode.py")

    if grouped_mistakes:
        for source_id, data in grouped_mistakes.items():
            with st.expander(f"**{data['name']}** ({len(data['mistakes'])} é“é”™é¢˜)"):
                # ... (é”™é¢˜æœ¬å†…éƒ¨é€»è¾‘ä¿æŒä¸å˜)
                for i, (question, log) in enumerate(data['mistakes']):
                    st.markdown(f"**é”™é¢˜ {i+1} (ID: {question.id})**: {json.loads(question.content)['question']}")
                    st.error(f"**ä½ çš„é”™è¯¯ç­”æ¡ˆ**: {log.user_answer}")
                    correct_answer_text = "è§£æå¤±è´¥"
                    try:
                        content = json.loads(question.content)
                        answer_data = json.loads(question.answer)
                        if question.question_type == "å•é¡¹é€‰æ‹©é¢˜": correct_answer_text = content["options"][answer_data["correct_option_index"]]
                        elif question.question_type == "åˆ¤æ–­é¢˜": correct_answer_text = "æ­£ç¡®" if answer_data["correct_answer"] else "é”™è¯¯"
                        elif question.question_type == "å¡«ç©ºé¢˜": correct_answer_text = ", ".join(answer_data["blanks"])
                        elif question.question_type == "ç®€ç­”é¢˜": correct_answer_text = answer_data["text"]
                    except Exception: pass
                    st.success(f"**æ­£ç¡®ç­”æ¡ˆ**: {correct_answer_text}")
                    if question.analysis:
                        st.info(f"**è§£æ**: {question.analysis}")
                    st.divider()
    else:
        st.success("å¤ªæ£’äº†ï¼æ‰€é€‰èŒƒå›´å†…æ²¡æœ‰å‘ç°é”™é¢˜ã€‚")