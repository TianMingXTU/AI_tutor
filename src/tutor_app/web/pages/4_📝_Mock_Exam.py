# src/tutor_app/web/pages/4_ğŸ“_Mock_Exam.py
import streamlit as st
import json
import time
import re
import pandas as pd
from datetime import timedelta
from src.tutor_app.db.session import SessionLocal
from src.tutor_app.db.models import KnowledgeSource
# ã€ä¼˜åŒ–1ã€‘å¯¼å…¥æ‰€æœ‰éœ€è¦çš„å‡½æ•°å’Œæ¨¡å‹
from src.tutor_app.crud.crud_question import (
    get_question_batch_with_type_selection, 
    save_exam_and_get_id, 
    save_exam_result,
    create_log_for_grading,
    get_grading_results
)
from src.tutor_app.tasks.grading import grade_short_answer_task
from src.tutor_app.web.components.task_monitor import display_global_task_monitor

st.set_page_config(page_title="æ¨¡æ‹Ÿè€ƒè¯•", layout="wide")
display_global_task_monitor()
st.title("ğŸ“ æ¨¡æ‹Ÿè€ƒè¯•æ¨¡å¼")

# ... (analyze_exam_by_tag, question_to_dict, Session State åˆå§‹åŒ–ä¿æŒä¸å˜)
def analyze_exam_by_tag(questions, user_answers):
    tag_stats = {}
    for q in questions:
        q_id = q['id']
        tag = q.get('knowledge_tag')
        if not tag: continue
        if tag not in tag_stats: tag_stats[tag] = {"correct": 0, "total": 0}
        tag_stats[tag]["total"] += 1
        user_ans = user_answers.get(q_id)
        is_correct = False
        try:
            content = json.loads(q['content'])
            answer_data = json.loads(q['answer'])
            if q['question_type'] == "å•é¡¹é€‰æ‹©é¢˜":
                correct_answer_text = content["options"][answer_data["correct_option_index"]]
                if user_ans == correct_answer_text: is_correct = True
            elif q['question_type'] == "åˆ¤æ–­é¢˜":
                correct_answer_text = "æ­£ç¡®" if answer_data["correct_answer"] else "é”™è¯¯"
                if user_ans == correct_answer_text: is_correct = True
        except Exception: pass
        if is_correct: tag_stats[tag]["correct"] += 1
    if not tag_stats: return pd.DataFrame()
    df_data = []
    for tag, stats in tag_stats.items():
        accuracy = (stats['correct'] / stats['total'] * 100) if stats['total'] > 0 else 0
        df_data.append({"çŸ¥è¯†ç‚¹": tag, "é¢˜ç›®æ€»æ•°": stats['total'], "ç­”å¯¹é¢˜æ•°": stats['correct'], "æ­£ç¡®ç‡(%)": round(accuracy, 2)})
    return pd.DataFrame(df_data)

def question_to_dict(q):
    return {"id": q.id, "question_type": q.question_type, "content": q.content, "answer": q.answer, "analysis": q.analysis, "knowledge_tag": q.knowledge_tag}

if 'exam_state' not in st.session_state: st.session_state.exam_state = "setup"
if 'exam_questions' not in st.session_state: st.session_state.exam_questions = []
if 'exam_id' not in st.session_state: st.session_state.exam_id = None
if 'exam_result' not in st.session_state: st.session_state.exam_result = None
if 'exam_end_time' not in st.session_state: st.session_state.exam_end_time = None


if st.session_state.exam_state == "setup":
    # ... (è®¾ç½®ç•Œé¢ä»£ç ä¿æŒä¸å˜)
    with st.container(border=True):
        st.header("è€ƒè¯•è®¾ç½®")
        db = SessionLocal()
        completed_sources = db.query(KnowledgeSource).filter(KnowledgeSource.status == 'completed').all()
        
        if completed_sources:
            source_options = {f"{s.id}: {s.filename}": s.id for s in completed_sources}
            
            selected_source_names = st.multiselect(
                "è¯·é€‰æ‹©è€ƒè¯•èŒƒå›´ (å¯å¤šé€‰çŸ¥è¯†åº“):",
                options=list(source_options.keys()),
                default=list(source_options.keys())[0] if source_options else []
            )
            selected_source_ids = [source_options[name] for name in selected_source_names]

            st.subheader("é…ç½®è¯•å·é¢˜å‹å’Œæ•°é‡")
            available_types = ["å•é¡¹é€‰æ‹©é¢˜", "åˆ¤æ–­é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜"]
            selected_types = st.multiselect("è¯·é€‰æ‹©è¯•å·åŒ…å«çš„é¢˜å‹:", options=available_types, default=["å•é¡¹é€‰æ‹©é¢˜", "åˆ¤æ–­é¢˜", "ç®€ç­”é¢˜"])
            type_counts = {}
            if selected_types:
                cols = st.columns(len(selected_types))
                for i, q_type in enumerate(selected_types):
                    with cols[i]:
                        type_counts[q_type] = st.number_input(f"â€œ{q_type}â€æ•°é‡:", min_value=1, max_value=50, value=2, key=f"exam_num_{q_type}")
            
            total_q_count = sum(type_counts.values()) if type_counts else 0
            exam_duration_minutes = st.number_input("è®¾ç½®è€ƒè¯•æ—¶é•¿ï¼ˆåˆ†é’Ÿï¼‰:", min_value=1, value=int(total_q_count * 1.5))
            st.divider()

            if st.button("ç”Ÿæˆè¯•å·å¹¶å¼€å§‹è€ƒè¯•", type="primary", use_container_width=True):
                if selected_source_ids and type_counts:
                    questions_from_db = get_question_batch_with_type_selection(db, "æ··åˆæ¨¡å¼", type_counts, selected_source_ids)
                    
                    if questions_from_db:
                        type_order = ["å•é¡¹é€‰æ‹©é¢˜", "åˆ¤æ–­é¢˜", "å¡«ç©ºé¢˜", "ç®€ç­”é¢˜"]
                        sorted_questions = sorted(questions_from_db, key=lambda q: type_order.index(q.question_type))
                        st.session_state.exam_questions = [question_to_dict(q) for q in sorted_questions]
                        question_ids = [q['id'] for q in st.session_state.exam_questions]
                        exam_title = f"ç»¼åˆè€ƒè¯•: {', '.join(selected_source_names)}"
                        st.session_state.exam_id = save_exam_and_get_id(db, selected_source_ids[0], exam_title, question_ids)
                        st.session_state.exam_end_time = time.time() + exam_duration_minutes * 60
                        st.session_state.exam_state = "running"
                        db.close()
                        st.rerun()
                    else:
                        st.error("æ‰€é€‰çŸ¥è¯†åº“ä¸‹æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„é¢˜ç›®æ¥ç”Ÿæˆè¯•å·ï¼")
                else:
                    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªçŸ¥è¯†åº“å’Œä¸€ç§é¢˜å‹ã€‚")
        else:
            st.warning("æ²¡æœ‰å¯ç”¨äºè€ƒè¯•çš„çŸ¥è¯†åº“ã€‚")
        
        if 'db' in locals() and db.is_active:
            db.close()

elif st.session_state.exam_state == "running":
    # ... (è€ƒè¯•è¿›è¡Œä¸­ç•Œé¢ä»£ç ä¿æŒä¸å˜)
    with st.sidebar:
        st.header("â³ è€ƒè¯•å€’è®¡æ—¶")
        timer_placeholder = st.empty()
    remaining_time = st.session_state.exam_end_time - time.time()
    if remaining_time > 0:
        timer_placeholder.metric("å‰©ä½™æ—¶é—´", str(timedelta(seconds=int(remaining_time))))
    else:
        timer_placeholder.error("æ—¶é—´åˆ°ï¼è¯·å°½å¿«äº¤å·ï¼")
    
    st.header("è€ƒè¯•è¿›è¡Œä¸­...")
    st.info(f"è¯•å·é¢˜ç›®æ•°é‡: {len(st.session_state.exam_questions)} é“")
    with st.form("exam_form"):
        user_answers = {}
        for i, q in enumerate(st.session_state.exam_questions):
            q_id = q['id']
            st.subheader(f"ç¬¬ {i+1} é¢˜: {q['question_type']}")
            try:
                content = json.loads(q['content'])
                if q['question_type'] in ["å•é¡¹é€‰æ‹©é¢˜", "åˆ¤æ–­é¢˜"]:
                    st.write(content["question"])
                    options = content.get("options", ["æ­£ç¡®", "é”™è¯¯"])
                    user_answers[q_id] = st.radio("ä½ çš„ç­”æ¡ˆ:", options, key=f"exam_q_{q_id}", index=None, horizontal=True)
                elif q['question_type'] == "ç®€ç­”é¢˜":
                    st.write(content["question"])
                    user_answers[q_id] = st.text_area("ä½ çš„ç­”æ¡ˆ:", key=f"exam_q_{q_id}")
                elif q['question_type'] == "å¡«ç©ºé¢˜":
                    stem = content["stem"]
                    num_blanks = stem.count("___")
                    display_stem = re.sub(r'___', lambda m, c=iter(range(1, num_blanks + 1)): f"__({next(c)})__", stem)
                    st.markdown(f"{display_stem}")
                    blanks_answers = []
                    cols = st.columns(num_blanks or 1)
                    for j in range(num_blanks):
                        with cols[j]:
                            blanks_answers.append(st.text_input(f"å¡«ç©º {j+1}", key=f"exam_q_{q_id}_blank_{j}"))
                    user_answers[q_id] = blanks_answers
            except Exception as e:
                st.error(f"é¢˜ç›®(ID: {q_id})æ¸²æŸ“å¤±è´¥ï¼Œæœ¬é¢˜å°†æ— æ³•è®¡åˆ†ã€‚é”™è¯¯: {e}")
                continue
        
        submitted = st.form_submit_button("äº¤å·å¹¶æŸ¥çœ‹ç»“æœ")
        if submitted or remaining_time <= 0:
            db = SessionLocal()
            try:
                # --- ã€ä¼˜åŒ–2: äº¤å·æ—¶è§¦å‘AIè¯„åˆ†ã€‘ ---
                score = 0
                total = len(st.session_state.exam_questions)
                grading_log_ids_map = {}

                for q in st.session_state.exam_questions:
                    q_id = q['id']
                    user_ans = user_answers.get(q_id)
                    
                    if q['question_type'] == "ç®€ç­”é¢˜" and user_ans and user_ans.strip():
                        # 1. ä¸ºç®€ç­”é¢˜åˆ›å»ºè¯„åˆ†æ—¥å¿—
                        log_id = create_log_for_grading(db, q_id, user_ans)
                        grading_log_ids_map[q_id] = log_id
                        # 2. æ´¾å‘å¼‚æ­¥è¯„åˆ†ä»»åŠ¡
                        grade_short_answer_task.delay(log_id)
                    else:
                        # 3. ä¸ºå®¢è§‚é¢˜ç›´æ¥è¯„åˆ†
                        is_correct = False
                        try:
                            content = json.loads(q['content'])
                            answer_data = json.loads(q['answer'])
                            if q['question_type'] == "å•é¡¹é€‰æ‹©é¢˜":
                                correct_answer_text = content["options"][answer_data["correct_option_index"]]
                                if user_ans == correct_answer_text: is_correct = True
                            elif q['question_type'] == "åˆ¤æ–­é¢˜":
                                correct_answer_text = "æ­£ç¡®" if answer_data["correct_answer"] else "é”™è¯¯"
                                if user_ans == correct_answer_text: is_correct = True
                            if is_correct:
                                score += 1
                        except Exception:
                            continue
                
                # 4. ä¿å­˜è€ƒè¯•ç»“æœï¼ŒåŒ…æ‹¬ç®€ç­”é¢˜çš„log_idæ˜ å°„
                save_exam_result(
                    db, st.session_state.exam_id, score, total, 
                    {k: str(v) for k, v in user_answers.items() if v is not None},
                    grading_log_ids_map
                )
                
                # 5. æ›´æ–° session_state
                st.session_state.exam_result = {
                    "score": score, "total": total, "questions": st.session_state.exam_questions,
                    "user_answers": user_answers,
                    "grading_log_ids": grading_log_ids_map
                }
                st.session_state.exam_state = "finished"
                st.rerun()
            finally:
                db.close()

    if remaining_time > 0:
        time.sleep(1)
        st.rerun()

elif st.session_state.exam_state == "finished":
    result = st.session_state.exam_result
    st.header("è€ƒååˆ†ææŠ¥å‘Š")
    st.balloons()
    
    tag_analysis_df = analyze_exam_by_tag(result['questions'], result['user_answers'])
    
    # --- ã€ä¼˜åŒ–3: åœ¨æŠ¥å‘Šä¸­æŸ¥è¯¢å¹¶å±•ç¤ºAIè¯„åˆ†ç»“æœã€‘ ---
    grading_log_ids = result.get("grading_log_ids", {})
    db = SessionLocal()
    try:
        grading_results = get_grading_results(db, list(grading_log_ids.values()))
    finally:
        db.close()

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š æˆç»©æ€»è§ˆ", "ğŸ·ï¸ çŸ¥è¯†ç‚¹è¯Šæ–­", "ğŸ” é€é¢˜å›é¡¾"])
    
    with tab1:
        # ... (æˆç»©æ€»è§ˆä»£ç ä¸å˜)
        st.subheader("æœ¬æ¬¡è€ƒè¯•æˆç»©")
        cols = st.columns(3)
        cols[0].metric("æœ€ç»ˆå¾—åˆ†", f"{result['score']} / {result['total']}")
        accuracy = (result['score'] / result['total'] * 100) if result['total'] > 0 else 0
        cols[1].metric("æ­£ç¡®ç‡", f"{accuracy:.1f}%")
        cols[2].metric("é¢˜ç›®æ€»æ•°", result['total'])
    
    with tab2:
        # ... (çŸ¥è¯†ç‚¹è¯Šæ–­ä»£ç ä¸å˜)
        st.subheader("æœ¬æ¬¡è€ƒè¯•çŸ¥è¯†ç‚¹è¯Šæ–­")
        if not tag_analysis_df.empty:
            st.info("è¿™ä»½è¯Šæ–­æŠ¥å‘Šåˆ†æäº†æ‚¨åœ¨æœ¬æ¬¡è€ƒè¯•ä¸­ï¼Œå„ä¸ªçŸ¥è¯†ç‚¹çš„è¡¨ç°ã€‚è¯·é‡ç‚¹å…³æ³¨æ­£ç¡®ç‡è¾ƒä½çš„ç¯èŠ‚ã€‚")
            sorted_df = tag_analysis_df.sort_values(by='æ­£ç¡®ç‡(%)', ascending=True)
            st.dataframe(sorted_df, use_container_width=True)
            st.bar_chart(sorted_df.set_index('çŸ¥è¯†ç‚¹')['æ­£ç¡®ç‡(%)'])
        else:
            st.warning("æœ¬æ¬¡è€ƒè¯•çš„é¢˜ç›®ç¼ºå°‘çŸ¥è¯†ç‚¹æ ‡ç­¾ï¼Œæ— æ³•ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šã€‚")

    with tab3:
        st.subheader("é¢˜ç›®è¯¦æƒ…å›é¡¾")
        for i, q in enumerate(result['questions']):
            q_id = q['id']
            with st.expander(f"ç¬¬ {i+1} é¢˜ ({q['question_type']}): {json.loads(q['content']).get('question', '')[:30]}..."):
                st.markdown(f"**é¢˜ç›®**: {json.loads(q['content']).get('question', 'é¢˜ç›®åŠ è½½å¤±è´¥')}")
                user_ans = result['user_answers'].get(q_id)
                st.error(f"**ä½ çš„ç­”æ¡ˆ**: {user_ans or 'æœªä½œç­”'}")

                if q['question_type'] == "ç®€ç­”é¢˜":
                    log_id = grading_log_ids.get(q_id)
                    log_entry = grading_results.get(log_id)
                    if log_entry and log_entry.ai_score:
                        score_map = {"æ­£ç¡®": "success", "éƒ¨åˆ†æ­£ç¡®": "warning", "é”™è¯¯": "error"}
                        score_type = score_map.get(log_entry.ai_score, "info")
                        getattr(st, score_type)(f"**AI è¯„ä»·**: {log_entry.ai_score}")
                        st.info(f"**AI è¯„è¯­**: {log_entry.ai_feedback}")
                    else:
                        st.info("ğŸ¤– AI åŠ©æ•™æ­£åœ¨æ‰¹é˜…æ‚¨çš„ç­”æ¡ˆï¼Œè¯·ç¨ååˆ·æ–°...")
                else: # å®¢è§‚é¢˜
                    try:
                        content = json.loads(q['content'])
                        answer_data = json.loads(q['answer'])
                        correct_answer_text = ""
                        if q['question_type'] == "å•é¡¹é€‰æ‹©é¢˜":
                            correct_answer_text = content["options"][answer_data["correct_option_index"]]
                        elif q['question_type'] == "åˆ¤æ–­é¢˜":
                            correct_answer_text = "æ­£ç¡®" if answer_data["correct_answer"] else "é”™è¯¯"
                        st.success(f"**æ­£ç¡®ç­”æ¡ˆ**: {correct_answer_text}")
                    except:
                        st.warning("ç­”æ¡ˆè§£æå¤±è´¥ã€‚")

                if q.get('analysis'):
                    with st.expander("ğŸ’¡ æŸ¥çœ‹åŸé¢˜è§£æ"):
                        st.info(f"**åŸé¢˜è§£æ**: {q['analysis']}")
            
    if st.button("è¿”å›è€ƒè¯•é¦–é¡µ", use_container_width=True):
        st.session_state.exam_state = "setup"
        st.session_state.exam_result = None
        st.rerun()